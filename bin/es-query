#!/usr/bin/env ruby

require 'elasticsearch'
require 'json'
require 'date'
require 'optparse'
require 'progress_bar'
require 'curb'

############ CONFIG ###########
$config = {}
$config[:host] = "ls2-es-lb.int.tropo.com"
$config[:port] = "9200"
$config[:scroll_size] = 10  ## Number of hits returned per scroll request. Not sure what to use here...
$config[:scroll_time] = '30m'   
$config[:report] = nil
$debug = nil
$types = [ "Asr", "Tts" ]
$flush_buffer = 1000 ## Number of log lines to flush to file at
$new_transport = true

$vendors = JSON.parse(IO.read(File.expand_path("../../etc/voices.json", __FILE__)))
##################################

def flush_to_file(hit_list)
    File.open($config[:output], 'a') do |file|
        begin
            file.puts(hit_list)
        rescue
            puts "Could not open output file (#{$config[:output]}) for writing!"
            exit
        end
    end
end

def validate_date(str)
    return true if str =~ /20[0-9]{2}-(0[1-9]|1[012])-(0[1-9]|[12][0-9]|3[01])T[012][0-9]:[0-5][0-9]:[0-5][0-9]\.[0-9]{3}Z/
    return nil
end

## Prints numbers with commas
def print_num(min)
    min.to_s.reverse.gsub(/(\d{3})(?=\d)/, '\\1,').reverse
end

def gen_report(data,title,is_vendor = nil)
    csv_dat = ''
    tab = '    '
    buffer = 20
    print "\n"
    puts "-----------------"
    puts "#{title} Totals:"
    puts "-----------------"

    print "#{tab}"
    [ "Voice", "Seconds" ].each do |slot|
        print "#{slot}"
        (buffer-slot.length).times { print ' ' }
    end

    puts
    45.times { print '-' }
    puts

    if is_vendor
        $vendors.keys.each do |vendor|
            $types.each do |type|
                seconds = data[type][vendor].to_i
                seconds = seconds / 1000
                print "#{tab}#{vendor}/#{type}"
                (buffer-vendor.length).times { print ' '}
                puts print_num seconds
                csv_dat = "#{title},#{vendor}/#{type},#{seconds}"
            end
        end     
    else
        data.each do |voice,seconds|
            ## Skip vendors
            next if $vendors.keys.each.include?(voice) 

            seconds = seconds / 1000
            voice = "Total #{title}" if voice =~ /cdr/
            print "#{tab}#{voice}"
            (buffer-voice.length).times { print ' ' }
            puts print_num seconds

            #CSV
            csv_dat += "#{title},#{voice},#{seconds}\n"
        end
    end

    return csv_dat

end

OptionParser.new do |opts|
    opts.banner = "Usage: "
    opts.on('-c','--connect_host [HOST]', "Logstash host to run query on (defaults to: #{$config[:host]})") { |v| $config[:host] = v unless v.empty? or v.nil? }
    opts.on('-p','--port [PORT]', "Logstash port (defaults to: #{$config[:port]})") { |v| $config[:port] = v unless v.empty? or v.nil? }
    opts.on('-w', '--write [FILE]', 'Write output file location (defaults to nil)') { |v| $config[:output] = v }
    opts.on('-r', '--report', 'Generate Asr/Tts report on CDR data') { |v| $config[:report] = true }
    opts.on('-d', '--debug', 'Debug mode') { |v| $debug = true }

    opts.on('-s', '--start [DATE]', 'Start date. Format: YYYY-MM-DDThh:mm:ss.SSSZ. Ex: 2013-12-01T12:00:00.000Z') do |v| 
        if validate_date(v)
            $config[:start] = v
        else
            puts "Incorrect timestamp format for start date"
            exit
        end
    end

    opts.on('-e', '--end [DATE]', 'End date. Format: YYYY-MM-DDThh:mm:ss.SSSZ') do |v| 
        if validate_date(v)
            $config[:end] = v
        else
            puts "Incorrect timestamp format for end date"
            exit
        end
    end

    opts.on('-q', '--query [QUERY]', 'Query string') { |v| $config[:query] = "#{v}" unless v.empty? }
    opts.on('-t', '--tags [TAGS]', 'Tags to query. Comma delimited')  do |tags|  
        arr = tags.split(',')
        if arr.length > 1
            $config[:tags] = "tags:(" + arr.join(' AND ') + ")"
        else
            $config[:tags] = "tags:#{tags}"
        end
    end
    opts.parse!
end

## Cleanup output file
begin
    File.truncate($config[:output],0)
rescue
end

## Try a different transporter
if $new_transport
    require 'typhoeus'
    require 'typhoeus/adapters/faraday'

    transport_conf = lambda do |f|
        #f.response :logger
        f.adapter :typhoeus
    end
end

## Connect to ES server
begin
    if $new_transport
        transport = Elasticsearch::Transport::Transport::HTTP::Faraday.new hosts: [ { host: $config[:host], port: $config[:port] }], &transport_conf
        es = Elasticsearch::Client.new transport: transport
    else
        es = Elasticsearch::Client.new(:host => $config[:host], :port => $config[:port])
    end
rescue
    puts "Could not connect to Elasticsearch cluster: #{$config[:host]}:#{$config[:port]}"
    exit
end

time_range = "@timestamp:[#{$config[:start]} TO #{$config[:end]}]"
query = ''
query = "#{$config[:tags]} AND " if $config[:tags]
query = query + "#{$config[:query]} AND " if $config[:query] 
query = query + "#{time_range}"


if $config[:start] and $config[:end]
    start_str = $config[:start].split('T').first.split('-').join('.')
    s_year = start_str.split('.').first.to_i
    s_mo = start_str.split('.')[1].to_i
    s_day = start_str.split('.').last.to_i
    start_date = Date.new(s_year, s_mo, s_day)

    end_str = $config[:end].split('T').first.split('-').join('.')
    e_year = end_str.split('.').first.to_i
    e_mo = end_str.split('.')[1].to_i
    e_day = end_str.split('.').last.to_i
    end_date = Date.new(e_year, e_mo, e_day)

    indexes = Array.new
    (start_date..end_date).map do |day| 
        day = day.strftime('%Y.%m.%d')
        puts "DAY: #{day}" if $debug
        indexes << "logstash-cdr-#{day}"
        indexes << "logstash-#{day}"
    end
else
    puts "You have not specified a start and/or end timestamp for your query"
    puts "I will default to search all existing indices. This will cause"
    puts "the query to be extremely slow. Shall I continue? (y/n) "
    ans = gets 
    exit unless ans.downcase =~ /y/
    indexes << '_all'
end

## Make sure each index exists
good_indexes = Array.new
unless indexes.include?('_all')
    indexes.each do |index|
        good_indexes << index if es.indices.exists index: index
    end
    indexes = good_indexes
else
    indexes = [ '_all' ]
end


puts "Using these indices: #{indexes.join(',')}" if $debug

# Get scroll ID
puts "Running this query:"
puts "    #{query}"
index_str = indexes.join(',')
res = es.search index: index_str, q: query, search_type: 'scan', scroll: $config[:scroll_time], size: $config[:scroll_size], df: 'message'
scroll_id = res['_scroll_id']

scroll_ids = Array.new
scroll_ids << res['_scroll_id']
puts "Your query returns #{res['hits']['total']} results"
puts

puts res.inspect if $debug and res['hits']['total'] > 300000

if $config[:output]
    puts "Writing messages to file #{$config[:output]}..."
    bar = ProgressBar.new(res['hits']['total'])
    hit_list = ''
    total_lines = 0 if $debug
    while true
        res['hits']['hits'].each do |hit|
            hit_list += hit['_source']['message']
            if hit_list.lines.count % $flush_buffer == 0
                flush_to_file hit_list
                hit_list = ''
            end
        end

        bar.increment! res['hits']['hits'].length
        total_lines += res['hits']['hits'].length if $debug

        # Continue scroll through data
        begin
            res = es.scroll scroll: $config[:scroll_time], body: scroll_id
            scroll_id = res['_scroll_id']
            scroll_ids << res['_scroll_id']
        rescue => e
            puts "EXCEPTION"
            puts res.inspect
            raise e
        end

        begin
            break if res['hits']['hits'].length < 1
        rescue => e
            puts "RESULT TYPE: #{res.class}"
            puts res.inspect
            raise e
        end
    end

    flush_to_file hit_list

    ## Delete the scroll_ids to free up resources on the ES cluster
    ## Have to use direct API call until elasticsearch-ruby supports this
    scroll_ids.uniq.each do |scroll|
        puts "DELETE SCROLL:#{scroll}" if $debug
        puts
        begin
            Curl.delete("#{$config[:host]}:#{$config[:port]}/_search/scroll/#{scroll}")
        rescue
            puts "Delete failed" if $debug
        end
    end
end


if $config[:tags] =~ /cdr/ and $config[:output]
    if $config[:report].nil?
        puts "I noticed you are querying CDR data. Would you like to run Asr/Tts usage report? (y/n)"
        ans = gets
        exit unless ans.downcase =~ /y/
    end
    puts "Analyzing CDR logs..."    
    totals = Hash.new
    total = 0
    hits = Hash.new
    $types.each do |type|
        hits[type] = Hash.new
        $vendors.keys.each do |vendor|
            hits[type][vendor] = Hash.new
            hits[type][vendor][:total] = 0        
            hits[type][vendor][:list] = Array.new        
            totals[type] = Hash.new
            totals[type][vendor] = 0
        end
    end

    IO.foreach($config[:output]) do |line|
        total += 1
        # Skip empty stuff
        next if line == "" or line.empty? or line =~ /^(\s)*$/

        this_call = {}

        # Get the CDR JSON
        line = line.partition('text={"call":').last
        line = line[0..-3] if line[-1] == ']'
        line = line.gsub('\s','/')

        ## Special checks for truncated CDR's
        if line[-1] != '}'
            next if line == "" or line.empty? or line =~ /^(\s)*$/
            #rewind until we hit ',{'
            line = line.reverse.partition('{,}').last.reverse
            line = line + '}]}'
        end

        next unless line[-1] == '}'

        begin
            dat = JSON.parse(line)
        rescue
            next
        end

        # Parse the json, store values
        $types.each do |type|
            totals[type] = Hash.new if ! totals[type]
            $vendors.keys.each do |vendor|
                totals[type][vendor] = 0 if ! totals[type][vendor]
                begin
                    hits[type][vendor][:list].clear 
                rescue
                    hits[type][vendor][:list] = Array.new
                end
            end
            this_call[type] = Hash.new

            if dat[type].is_a? Array
                dat[type].each do |call|
                    name = call['ResourceName'].nil? ? "WHAT" : call['ResourceName']
                    name = call['ResourceName'].empty? ? "EMPTY" : call['ResourceName']
                    name.downcase!
                    this_call[type][name] = call['Duration'].to_i
                    this_call[:call_id] = dat['CallID']
                    this_call[:session_id] = dat['SessionID']

                    ## Check for multiple vendor voices per call
                    $vendors.keys.each do |vendor|
                        if $vendors[vendor]['voices'].include?(name) and ! hits[type][vendor][:list].include?(name)
                            hits[type][vendor][:list] << name
                        end
                    end
                end
            end

            ## Add this call to the totals
            this_call[type].keys.each do |name|
                if ! totals[type][name] or totals[type][name].nil?
                    totals[type][name] = this_call[type][name]
                else
                    totals[type][name] += this_call[type][name]
                end
            end
 
            ## Print data about multi-voice calls
            $vendors.keys.each do |vendor|
                voices = Array.new
                durations = Array.new
                if hits[type][vendor][:list].length > 1
                    hits[type][vendor][:total] += 1 
                    
                    ## Print callID, Voices/durations
                    this_call[type].keys.each do |voice_name|
                        voices << "#{voice_name}(#{this_call[type][voice_name]})" if $vendors[vendor]['voices'].include?(voice_name)
                        durations << this_call[type][voice_name] if $vendors[vendor]['voices'].include?(voice_name)
                    end
                    puts "#{type.upcase} CallID:#{this_call[:call_id]}, SessionID:#{this_call[:session_id]}, Vendor:#{vendor}, Voices: #{voices.join(', ')}" unless voices.empty? or ! $debug
            
                    ## vendor total calculations
                    puts "MAX:#{durations.max}" if $debug
                    totals[type][vendor] += durations.max.to_i

                else
                    this_call[type].keys.each do |name|
                        totals[type][vendor] += this_call[type][name] if $vendors[vendor]['voices'].include?(name)
                    end
                end
            end

        end #END types
        
    end #END each line
    
    puts
    puts

    $vendors.keys.each do |vendor|
        $types.each do |type|
            puts "Number of multi voice hits for #{vendor}, type #{type}: #{hits[type][vendor][:total]}"
        end
    end

    puts
    csv_dat = "Type,Voice,Seconds\n"

    $types.each do |type|
        csv_dat += gen_report(totals[type],type) if totals[type]
    end

    csv_dat += gen_report(totals,'Vendor',true)
end

puts csv_dat if $debug


